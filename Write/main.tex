\documentclass{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}% http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\usepackage{tikz-cd}
\usepackage[colorlinks, linkcolor = blue, citecolor = magenta]{hyperref}
\newenvironment{notation}
\newenvironment{remark}
\newenvironment{property}
\title{TenSyGrid}

\author{Pablo de Juan Vela $^{1}$ \\
        \small $^{1}$eRoots, Barcelona, Spain \\
}
\date{}

\begin{document}
\maketitle


\section{Tensor Notation}

A tensor is an N-way array where its values are accesed by N indeces. In this sense, a vector is an order 1 tensor and a matrix an order 2 tensor.
A tensor of order n in the real numbers can de defined as $F \in \mathbb{R}^{I_1 \times ... \times I_n}$, where $I_i$ is the dimension of the $i_{th}$ order.

\begin{notation}
    Let $F$ be a tensor in $F \in \mathbb{R}^{\times_2 n }$ of order $n$, where each dimension has legth $2$.
\end{notation}

\subsection{Tensor Operations}


\subsubsection*{Tensor Product}
Let $F \in \mathbb{R}^{ j_1 \times ... \times j_m}$ and  
$G \in \mathbb{R}^{i_1 \times ... \times i_n }$. Then the tensor product 
$F \otimes G \in \mathbb{R}^{j_1 \times ... \times j_m, i_1 \times ... \times i_n }$ has
the entries for $\forall a_k \in \{1,...,j_k\}, b_k \in \{1,...,i_k\}$:

\begin{equation}
    (F \otimes G)_{a_1 , ... ,a_m,b_1 , ... ,b_n  } := f_{a_1,...,a_m}.g_{b_1,...,b_m}
\end{equation}

\subsubsection*{Inner Product}

The inner product of two tensors of same order and dimension $F, G \in \mathbb{R}^{ j_1 \times ... \times j_m}$
is a scalar that has the same properties of a vector product and is defined as:  

\begin{equation}
    <F,G> = \sum_{d_1=1}^{j_1} \sum_{d_2=1}^{j_2} \cdots \sum_{d_n=1}^{j_n} a_{d_1 d_2 \ldots d_n} b_{d_1 d_2 \ldots d_n}
\end{equation}

This concept can be generalized for tensors of different dimensions. 
In this case the inner product can be interpreted as a form of order contraction.

\subsubsection*{Hadamard Product}

The Hadamard product between 2 tensors of equal dimensionw is the 
point wise multiplication of those 2 tensors. 
Let $F,G \in \mathbb{R}^{i_1,...,i_n}$ then we define $F\circledast G \in \mathbb{R}^{i_1,...,i_n}$
the Hadamard product of $F$ and $G$ such that:

\begin{equation}
    (F\circledast G )_{i_1,...,i_n} = F_{i_1,...,i_n}G_{i_1,...,i_n}
\end{equation}

\subsubsection*{Monomial Tensor}

Let $x \in \mathbb{R}^n$ a vector. Then $m(x) \in \mathbb{R}^{2^n}$ is a vector 
such that each entry is a unique multilinear monomial of coefficient 1.
More specifically, $m(x)$ is defined as follows:

\begin{equation}
    m(x) := \begin{pmatrix}
        1 \\
        x_1
    \end{pmatrix}
    \otimes ... \otimes
    \begin{pmatrix}
        1 \\
        x_n
    \end{pmatrix}
\end{equation}

Let $x \in \mathbb{R}^n$ a vector. We define $M(x) \in \mathbb{R}^{\times_2 n}$ as the monomial 
tensor that is defined as follows. We can see that $M(x)$ is a reshaping of the monomial vector
$m(x)$, $a_i \in \{0,1\} \forall i$.
\begin{equation}
    (M(x))_{a_1, ..., a_n} := \prod_{i=1}^{n} x_i^{a_i}
\end{equation}

\subsection{Properties}

Let $F \in \mathbb{R}^{\times_2 n \times p}$ be a tensor of order $n+1$.
And $\forall i \in \{0,..,n\} $ there exist $F_{x_i} \in \mathbb{R}^{2 \times r}$
and $F_\phi  \in \mathbb{R}^{p \times r}$ such that, where $F_{i}(k)$ is the $k_{th}$
column of $F_{x_i}$. 

\begin{equation}
    F = \sum_{k = 0}^r F_{x_1}(k) \otimes ... \otimes F_{x_n}(k) \otimes F_{x_\phi}(k) 
\end{equation}

Then we say that $[F_{x_1}, ..., F_{x_n}, F_\phi]$ is a decomposition of rank $r$ 
of $F$. Additionally, if we consider a vector $x \in \mathbb{R}^n$ we have that 
the following equation holds true:

\begin{equation}
    <F, M(x)> = F_{\phi}(F_{x_1}^T 
    \begin{pmatrix}
        1 \\
        x_1    
    \end{pmatrix}
    \circledast
    \dots
    \circledast
    F_{x_n}^T
    \begin{pmatrix}
        1 \\
        x_n    
    \end{pmatrix})
\end{equation}

\subsection{Tensor }

\section{Multilinear models}

A multi linear equation takes the form of:

\begin{align}
    p(x) &= \sum_{i_n = 0}^{i_n = 1}...\sum_{i_1 = 0}^{i_1 = 1} a_{i_1, ..., i_n} x_1^{i_1}...x_n^{i_n} \\ 
\end{align}

We can stablish a relationship between the coefficients of a multilinear polinomial in $x\mathbb{R}^{n}$ 
and the entries of a tensor $F \in \mathbb{R}^{\times_2 n}$. The following equation describes the relationship between
the multi linear polynomial $p(x)$ and a tensor $F$.

\begin{equation}
    F_{i_1,...,i_n} = a_{i_1, ..., i_n}
\end{equation}

\subsection{Multilinear Time Independent Models}

Multilinear Time Independent models or (MTI) describes a system and its evolution over time. 
The values used to define the system's operations are the following:

\begin{itemize}
    \item $x \in\mathbb{R}^n$ the state.   
    \item $y \in\mathbb{R}^p$ the output.   
    \item $u \in\mathbb{R}^m$ the input.   
\end{itemize}

Additionally, we need to consider the system's equations. 
Using the previous tensor notation we can describe the system equations explicitly as follows,
where $F \in \mathbb{R}^{\times_2 (n+m) \times n}$, $G \in \mathbb{R}^{\times_2 (n+m) \times p}$:

\begin{align}
    \dot{x} &= <F|M(x,u)>\\
    y &= <G|M(x,u)>
\end{align}

Another way to define an MTI's evolution is through the use of an implicit multilinear (iMTI) equation.
In this case the tensor $H \in \mathbb{R}^{\times_2 (2n+m+p) \times n+p}$ defines the state evolution. 
Additionnally, we would need to add the conditions $det(\partial_{\dot{x}} H) \neq 0$, $det(\partial_y H) \neq 0$ 
for the system to be properly defined (implicit function theorem). Otherwise, more equations would be needed to 
define the system completely.

\begin{equation}
    <H| M(\dot{x}, x, u, y)> = 0
\end{equation}

It is clear that the explicit formulation can be transformed into the implicit one such that the resulting system is:
Where $\overline{H}$ is chosen approprietely to represent the $(n+p)$ multilinear equations $\dot{x} - <F|M(x,u)> = 0$
and $y - <G|M(x,u)> = 0$.
\begin{equation}
    <\overline{H}| M(\dot{x}, x, u, y)> = 0
\end{equation}

\subsection{Differential Algebraic Equations}

Differential Algebraic Equations (DAE) are a set of problems defined by differential equations
and another set of algebraic equations. An explicit formulation of a DAE can be done as follows:
Where $x \in C(\mathbb{R}^n, \mathbb{R}), y \in C(\mathbb{R}^n, \mathbb{R}), t \in \mathbb{R}$

\begin{align}\label{DAE:explicit}
    \dot{x} &= f(x, z, t) \\
    0 &= g(x, z, t)
\end{align}

It is clear from the previous equation that ODEs are a special case of DAEs where $g(x,z,t) = 0$.
In general, DAEs are tighly linked with ODEs. One way to link them together is though the concept of index.
The (differential) index of a DAE is the number of times the equations  of the DAE
need to be differentiated in order to recover an explicit ODE. 
However, it is important to note that the index is dependent on the formulation of the DAE
as well as on the solution provided. Usually, a higher index means the DAE involves more complexity
specially when solving it numerically. \\

\begin{remark}
    The explicit form of a DAE is specifically useful since it enables To
    solve numerically the problem in a straighforward manner. First, considering the implicit function
    $aux(x, t)$ that yields a set of variables $z$ such that $g(x, aux(x,t), t) = 0$. And then substituting
    in the first equation. 
    In pseudo-code this yields:

    \begin{algorithm}
        \caption{Implicit Stepforward}
        \label{alg:implicit_stepforward}
        \begin{algorithmic}[1] % This number determines the starting line number
            \State Initialize {$x_0 \in X$} initial state.
            \State Initialize {$z_0 \in Z$} initial auxiliary variables.
            \For{$t = 0$ to $T$} 
                \State Define $aux(x,t)$
                \State Solve $f(x_{t+1}, aux(x_{t+1}, t+1), t+1) = 0$ for variable $x_{t+1}$.
                \State $x_{t+1} \leftarrow x*$
            \EndFor
        \end{algorithmic}
    \end{algorithm}
\end{remark} 

However, this method does not always yield good numerical results, specially with DAEs of higher index.
For this purpose, we will explore different numerical methods and analyse how they compare to each 
other and, more specifically, which one fits the type of DAE that we are studying best.

\section{Numerical Methods}

\subsection{Numerical Methods for ODE's}

ODEs can be represented by the following implicit equation:

\begin{equation}\label{ODE:implicit}
    f(x, \dot{x}, t) = 0
\end{equation}

One specific method to solve a system of ODE are implicit methods. 
This is a type of family of methods that discretizes the time variable into a set of timesteps
$\mathcal{T}:=\{1,...,T\}$. An initial value $x_0$ for $x$ is given and then the following values are 
found by solving an equation involving the function in \ref{ODE:implicit}. 
More specifically, we solve the equation $g(x_{t+1}, x_t) = 0$ where $x_t$ is known, $x_{t+1}$ is the unknown,
anf $g$ has the following expression:

\begin{equation}
    g(x_{t+1}, x_t) = f(x_{t+1}, \frac{x_{t+1}- x_t}{\Delta t}, t+1) 
\end{equation}

\begin{remark}
    This method consists of solving iteratively an implicit system of equations. 
    These type of systems are usually solved using Newton-Raphson methods. These methods
    demand a fixed number of evaluations of the function to be solved. 
    This means that, if we define $c$ as the number of calculations needed
    to evaluate the implicit function then the complexity of the algorithm is
    $\mathcal{O}(ct)$.
\end{remark}

We want to adapt this method to solve an explicit DAE as in \ref{DAE:explicit}. To do so we 
define a new function $\overline{F}(x,u)$ that can be used as the implicit function. 

\begin{equation}
    \overline{F}(\dot{x}, x, z, u) =
    \begin{pmatrix}
        \dot{x} - <F|M(x, z, u)> \\
        <G|M(x, z, u)>
    \end{pmatrix} 
\end{equation}

\begin{equation}
    \overline{G}(x_{t+1}, x_{t}, z_{t+1}, u_{t+1}) =  \overline{F}(\frac{x_{t+1}- x_t}{\Delta t}, x_{t}, z_{t+1}, u_{t+1})
\end{equation}

We can describe the method in algorithmic form as follows:

\begin{algorithm}
    \caption{Implicit Stepforward}
    \label{alg:implicit_stepforward}
    \begin{algorithmic}[1] % This number determines the starting line number
        \State Initialize {$x_0 \in X$} initial state.
        \State Initialize {$z_0 \in Z$} initial auxiliary variables.
        \For{$t = 0$ to $T$} 
            \State Solve for $x_{t+1}, z_{t+1}$,  $\overline{G}(x_{t+1}, x_{t}, z_{t+1}, u_{t+1}) = 0$
            \State $x_{t+1} \gets x*$ 
            \State $z_{t+1} \gets z*$
        \EndFor
    \end{algorithmic}
\end{algorithm}

\begin{remark}
    This method also consists of solving iteratively an implicit equation. 
    In this case we are solving, a system of $(n+m)$ equations. If we define $c(n,m)$
    as the number of calculations necessary to evaluate the function $f$.    
\end{remark}

\subsection*{Ill Conditioning \& Solvability}

A problem is said to be well posed if a solution to the problem exists and if said solution is unique.
In the case of the proposed algorithms the well posedness of the problem depends
on the well posedness of the intermediate Newton-Raphson methods. 
The most frequent problem that arise when dealing with  

\begin{property}
    Let $F,G$ the tensor defining a multilinear DAE in explicit formulation such that
    $det(G_z(x,z,t)) \neq 0 \forall x \in X, z \in Z, t \in \mathcal{T}$
    then  the algorithm \ref{alg:implicit_stepforward} is well posed. 
\end{property}

\subsection{Tensor Construction}

Let $F \in \mathbb{R}^{n,n,p}$ representing $p$ multilinear 
equations of order $2$. More specifically, $\forall k \in \{1,...,k\}$
the tensor $F$ represents the following polynomial $q_k(x)$: 

\begin{equation}
    q_k(x) = \sum_{i=1}^n \sum_{j=1}^n (\frac{1+\delta_{i,j}}{2}) x_i x_j F_{i,j,k}  
\end{equation}

The tensor $F$ can be decomposed as follows: 
\begin{align}
    F &= \sum_{r = 1}^R F_1(r) \otimes F_2(r) \otimes F_3(r) \\
    F_{i,j,k} &=\sum_{r = 1}^R F_1(i,r) F_2(j,r) F_3(k,r) 
\end{align}

We now consider the tensor $G \in \mathbb{R}^{\times_2n \times p}$. 
representing the order 2 multilinear equations as a full tensor. 
It is clear that in this case the tensor $G$ entries usually
take $0$ as a value. Indeed we have that:

\begin{equation}
    G_{i_1,...,i_n} = \left\{
        \begin{array}{ll}
            F_{i_k, i_l} & \text{if } i_k = i_l = 1, \sum_m i_m = 2\\
            0 & \text{otherwise}
        \end{array}
    \right.
\end{equation}


Therefore we want to take advantage of the sparsity of $G$ to find its 
decomposition.
Similarly as for $F$, the tensor $G$ can also be decompose, and each entry is equal to:
\begin{equation}
    G_{i_1,...,i_n} = \sum_{r = 1}^R G_1(i_1,r)\otimes ...\otimes G_n(i_n,r) 
\end{equation}

We want to derive from this equation a relationship between 
both decompositon however this is not alwyas easy.
Since we are dealing with an order 2, multilinear systems
we can express the equation in 

\begin{align}
    <F, x \otimes x> &= F \circledast (x \otimes x) \\
    &= (\sum_r f_1(r) \otimes f_2(r) ) \circledast (x \otimes x) \\
    &= \sum_r( f_1(r) \otimes f_2(r) ) \circledast (x \otimes x) \\
    &= \sum_r <f_1(r), x> <f_2(r), x> \\
\end{align}

When dealing with $p$ equations this can be generalized to \ref{eq:Fbilinear}
where $f_1, f_2 \in \mathbb{R}^{n \times p}$. However, this equation excludes
the lower order monomials, in this case
\begin{equation}\label{eq:Fbilinear}
    <F, x \otimes x> = \sum_{r=1}^R f_1(r)^T x \circledast f_2(r)^T x 
\end{equation}

If this is done for higher order polinomials of order $q$ we can find:
\begin{equation}
    <F, \otimes_{i = 1}^{q} x > = \sum_{r=1}^R f_1(r)^T x \circledast ... \circledast f_q(r)^T x 
\end{equation}

Finally, by combining the previous equations we 
can express a multilinear function of maximum order $q$ as follows,
where $F_{expanded} \in \mathbb{R}^{\times_{n+1}q \times p}$. The new change
includes all the lower order multinomial monomials. 

\begin{align}
    F_{expanded} = [F_0, F_1, ..., F_n, F_\phi]
    <F_{expanded}, \otimes_{i = 1}^{q}
    \begin{pmatrix}
        1 \\
        x
    \end{pmatrix}
    > = F_\phi( F_0^T \begin{pmatrix}
        1 \\
        x
    \end{pmatrix} \circledast \dots
    F_n^T \begin{pmatrix}
        1 \\
        x
    \end{pmatrix})
\end{align}

\subsection{Order $q$ polynomial model combination}

\section{Case Study 1}

For this case study we define a non linear EDO of the following form:
Where $x \in \mathcal{C}(\mathbb{R}^n, \mathbb{R})$, $A, B, C \in \mathbb{R}^{n \times n } $.
\begin{equation}
    \dot{x}(t) = Ax(t) + B(x(t) \odot x(t)) + x^T(t) C x(t)
\end{equation}

The equation represents an EDO with a linear component $A$ and a quadratic component $B$.
The objective is to transform this ODE into a multi linear DAE.
For this purpose, we add $n$ auxiliary variables in the form of the vector v as well as n algebraic equations.

\begin{align}
    B(x(t) \odot x(t)) \\
    \Leftrightarrow \left\{
        \begin{array}{ll}
            B(u(t) \odot x(t)) \\
            u(t) = x(t)
        \end{array}
    \right.
\end{align}

This yields the following multi linear DAE system:

\begin{align}
    \dot{x}(t) = Ax(t) + B(u(t) \odot x(t)) \\
    0 = u(t) - x(t)
\end{align}

\begin{equation}
    A =
    \begin{pmatrix}
        -0.5 & 0.1 & 0 & 0 & 0 \\
        0.5 & -0.2 & 0.1 & 0 & 0 \\
        0 & 0 & -0.3 & 0 & 0 \\
        0 & 0 & 0 & 0.4 & -0.1 \\
        0 & 0 & 0 & 0 & -0.2 \\
    \end{pmatrix},

    B = 
    \begin{pmatrix}
        0 & 0 & 0 & 0 & 0 \\
        0 & 0& 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & -0.1 \\
        0 & 0 & 0 & 0 & 0 \\
    \end{pmatrix},

    C = 
    \begin{pmatrix}
        0 & 0.05 & 0 & 0.1 & 0 \\
        0 & 0& 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & -0.1 \\
    \end{pmatrix}
\end{equation}

Finally we transform into the tenorsorized formulation of an iMTI.
Where $F, G \in \mathbb{R}^{\times_2 2n \times n}$
\begin{align}
    \dot{x}(t) &= <F|M(x,u)> \\
    0 &= <G|M(x,u)>
\end{align}


\begin{align}
    F_{i_1, ..., i_n, j_1, ...j_n, k} &= \left\{
        \begin{array}{ll}
            A_{k,l} & \text{if } i_l = 1 \text{ and } \sum_{m= 1}^n i_m + j_m = 1 \\
            B_{k,l} +  & \text{if } i_l = 1, j_l = 1 \text{ and } \sum_{m= 1}^n i_m + j_m = 2 \\
            0 & \text{otherwise} 
        \end{array}
    \right.\\
    G_{i_1, ..., i_n, j_1, ...j_n, k} &= \left\{
        \begin{array}{ll}
            1 & \text{if } i_l = 1, l=k \text{ and } \sum_{m= 1}^2 i_m + j_m = 1 \\
            -1 & \text{if } j_l = 1, l=k \text{ and } \sum_{m= 1}^2 i_m + j_m = 1 \\
            0 & \text{otherwise} 
        \end{array}
    \right.\\
\end{align}

\section{Case Study 2}

For this case study we define a non linear EDO of the following form:
Where $x \in \mathcal{C}(\mathbb{R}^n, \mathbb{R})$, $A_i \in \mathbb{R}^{n \times n } \quad \forall i$.
\begin{equation}
    \dot{x}_i(t) = x^T(t) A_i x(t) \ \ \forall i \in \{1,...,n\} 
\end{equation}

Using the same procedure done in the first case study we build the explicit multilinear tensor equations defining the model.
\begin{align}
    \dot{x}(t) &= <F|M(x,u)> \\
    0 &= <G|M(x,u)>
\end{align}

\begin{align}
    F_{i_1, ..., i_n, j_1, ...j_n, k} &= \left\{
        \begin{array}{ll}
            A_{k,l,m} + A_{k,m,l} & \text{if } l \neq m, \quad i_l = 1, i_m = 1 \text{ and } \sum_{m= 1}^n i_m + j_m = 2 \\
            A_{k,l,l} & \text{if } i_l = 1, j_l = 1 \text{ and } \sum_{m= 1}^n i_m + j_m = 2 \\
            0 & \text{otherwise} 
        \end{array}
    \right.\\
    G_{i_1, ..., i_n, j_1, ...j_n, k} &= \left\{
        \begin{array}{ll}
            1 & \text{if } i_l = 1, l=k \text{ and } \sum_{m= 1}^n i_m + j_m = 1 \\
            -1 & \text{if } j_l = 1, l=k \text{ and } \sum_{m= 1}^n i_m + j_m = 1 \\
            0 & \text{otherwise} 
        \end{array}
    \right.\\
\end{align}

Let's us now analyze the DAE's index. By virtue of the equations being in 
explicit form the first equation are already a ODE so they are of differential index 0.
On the other hand the algbraic equations consist exclusively of equations of the form $u_i = x_i$, therefore differentiating the $n$ equations once already gives a EDO.
This means that the DAE in this form is of index $1$. 

\end{document}